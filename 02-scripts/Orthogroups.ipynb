{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b05c9bd3",
   "metadata": {},
   "source": [
    "## 1. Identification of orthologue proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567d7d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9085b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando arquivo\n",
    "ortogrupos = pd.read_csv(\"../03-analysis/03.01-orthofinder/Orthogroups/Orthogroups.tsv\", sep=\"\\t\")\n",
    "# Removendo NAs, extraindo pares de ortologs\n",
    "ortologos_zh = ortogrupos.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c57af",
   "metadata": {},
   "source": [
    "## Genomics statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70538fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orthogroup</th>\n",
       "      <th>Human.UniProt.renamed</th>\n",
       "      <th>Zebrafish.UniProt.renamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OG0000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0A0G2KC95, A0A0G2KGX6, A0A0G2KLW9, A0A0G2KMQ4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OG0000001</td>\n",
       "      <td>Q8N8Y5, Q9BWE0</td>\n",
       "      <td>A0A0G2KE12, A0A0G2KH00, A0A0G2KSD8, A0A0G2L2X0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OG0000002</td>\n",
       "      <td>P17041</td>\n",
       "      <td>A0A0G2KI00, A0A0G2KLM8, A0A0G2KZN8, A0A0G2L199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OG0000003</td>\n",
       "      <td>A0A2R8Y4L6, A0A2R8YED5, A6ND48, A6NDH6, A6NET4...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OG0000004</td>\n",
       "      <td>P17026, Q49A33, Q6ZT77, Q7Z3I7, Q8N3J9</td>\n",
       "      <td>A0A0R4IS41, A0A0R4IX00, A0A8M1PS56, A0A8M2BBI2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Orthogroup                              Human.UniProt.renamed  \\\n",
       "0  OG0000000                                                NaN   \n",
       "1  OG0000001                                     Q8N8Y5, Q9BWE0   \n",
       "2  OG0000002                                             P17041   \n",
       "3  OG0000003  A0A2R8Y4L6, A0A2R8YED5, A6ND48, A6NDH6, A6NET4...   \n",
       "4  OG0000004             P17026, Q49A33, Q6ZT77, Q7Z3I7, Q8N3J9   \n",
       "\n",
       "                           Zebrafish.UniProt.renamed  \n",
       "0  A0A0G2KC95, A0A0G2KGX6, A0A0G2KLW9, A0A0G2KMQ4...  \n",
       "1  A0A0G2KE12, A0A0G2KH00, A0A0G2KSD8, A0A0G2L2X0...  \n",
       "2  A0A0G2KI00, A0A0G2KLM8, A0A0G2KZN8, A0A0G2L199...  \n",
       "3                                                NaN  \n",
       "4  A0A0R4IS41, A0A0R4IX00, A0A8M1PS56, A0A8M2BBI2...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('../03-analysis/03.01-orthofinder/Orthogroups/Orthogroups.tsv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c37997",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.str.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43e1c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para categorizar com base nas condições especificadas\n",
    "def categorize(row):\n",
    "\n",
    "    if pd.notna(row['Human.UniProt.renamed']) and pd.notna(row['Zebrafish.UniProt.renamed']):\n",
    "        if len(row['Human.UniProt.renamed']) == 1 and len(row['Zebra.UniProt.renamed']) == 1:\n",
    "            return 'one-to-one'\n",
    "        elif len(row['Zebra.UniProt.renamed']) > 1 and len(row['Human.UniProt.renamed']) > 1:\n",
    "            return 'many-to-many'\n",
    "        else:\n",
    "            return 'one-to-many'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67370711",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterEnv/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterEnv/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterEnv/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/miniconda3/envs/jupyterEnv/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36mcategorize\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcategorize\u001b[39m(row):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuman.UniProt.renamed\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZebrafish.UniProt.renamed\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHuman.UniProt.renamed\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZebra.UniProt.renamed\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      6\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone-to-one\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "df['category'] = df.apply(categorize, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ec213",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e4090",
   "metadata": {},
   "source": [
    "## 2. Protein alignment and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dedd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from Bio import SeqIO, Align\n",
    "from Bio.Align import substitution_matrices, AlignInfo\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "# Definindo os diretórios\n",
    "orthologues_dir = '../orthofinder/Orthogroups'\n",
    "orthogroup_sequences_dir = '../orthofinder/Orthogroup_Sequences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b10bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para ler o arquivo Orthologues.tsv e criar a lista de nomes\n",
    "def ler_orthologues_tsv(orthologues_path):\n",
    "    orthologues_df = pd.read_csv(orthologues_path, sep='\\t')\n",
    "    orthologues_df.dropna(inplace=True)\n",
    "    return list(orthologues_df.iloc[:, 0])\n",
    "\n",
    "# Função para carregar sequências em um arquivo FASTA para SeqRecord\n",
    "def carregar_seqrecord(fasta_path):\n",
    "    return list(SeqIO.parse(fasta_path, 'fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b0e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo parametros do alinhamento\n",
    "matrix = substitution_matrices.load(\"BLASTP\")\n",
    "aligner = Align.PairwiseAligner()\n",
    "aligner.substitution_matrix = matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "088260cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os ortogrupos de interesse\n",
    "orthogroups = ler_orthologues_tsv(os.path.join(orthologues_dir, 'Orthogroups.tsv'))\n",
    "orthogroupSeqRecord = carregar_seqrecord(os.path.join(orthogroup_sequences_dir, f'{orthogroups[20]}.fa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4387ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_list = list(combinations(orthogroupSeqRecord,2))\n",
    "\n",
    "alignments = aligner.align(combination_list[0][0], combination_list[0][1])\n",
    "alignment = alignments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60ff16",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc78b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler os ortogrupos de interesse\n",
    "orthogroups = ler_orthologues_tsv(os.path.join(orthologues_dir, 'Orthogroups.tsv'))\n",
    "\n",
    "# Inicializar o dataframe vazio\n",
    "df_results = []\n",
    "\n",
    "# Carregar as sequências de cada ortogrupo e alinhar os pares de sequências\n",
    "for orthogroup in orthogroups:\n",
    "    orthogroupSeqRecord = carregar_seqrecord(os.path.join(orthogroup_sequences_dir, f'{orthogroup}.fa'))\n",
    "\n",
    "    results = []\n",
    "    combination_list = list(combinations(orthogroupSeqRecord,2))\n",
    "\n",
    "    for i in range(len(combination_list)):\n",
    "        alignments = aligner.align(combination_list[i][0], combination_list[i][1])\n",
    "        alignment = alignments[0]\n",
    "  \n",
    "        results.append({\n",
    "        \"orthogroup\" : f'{orthogroup}',\n",
    "        \"query_id\": alignment.query.id,\n",
    "        \"target_id\": alignment.target.id,\n",
    "        \"per_identity\": round((alignment.counts()[1] * 100)/alignment.length, 2),\n",
    "        \"length\": alignment.length,\n",
    "        \"query_start\": alignment.coordinates[0][0],\n",
    "        \"query_end\": alignment.coordinates[0][-1],\n",
    "        \"query_cover\": ((alignment.coordinates[0][-1] - alignment.coordinates[0][0] + 1)/len(alignment.query)) * 100,\n",
    "        \"subject_start\": alignment.coordinates[1][0],\n",
    "        \"subject_end\": alignment.coordinates[1][-1],\n",
    "        'subject_cover': ((alignment.coordinates[1][-1] - alignment.coordinates[1][0] + 1)/len(alignment.target)) * 100,\n",
    "        \"score\": round(alignment.score, 2),\n",
    "        \"gaps\": alignment.counts()[0],\n",
    "        \"identities\": alignment.counts()[1],\n",
    "        \"mismatches\": alignment.counts()[2]\n",
    "    })\n",
    "    \n",
    "    df_results.append(pd.DataFrame(results))\n",
    "    \n",
    "dfFinal = pd.concat(df_results)\n",
    "dfFinal.to_csv('../results/orthogroup_alignments.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1834f07",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a3d49",
   "metadata": {},
   "source": [
    "## 3. Selection of epilepsy targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db3fc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas\n",
    "import pandas as pd\n",
    "from unipressed import IdMappingClient\n",
    "import time\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c42a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "epilepsy_genes = pd.read_excel(\"../00-documentation/EpilepsyGene_1482_IDs_EGNF.xlsx\")\n",
    "epilepsy_genes.drop(columns=[\"UniProt_ID\"], inplace=True)\n",
    "epilepsy_genes[\"Entrez_ID\"] = epilepsy_genes[\"Entrez_ID\"].astype(str)\n",
    "\n",
    "# Getting the Entrez IDs and converting them to UniProt IDsa\n",
    "entrez_epi = epilepsy_genes[\"Entrez_ID\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aff40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting matches IDs\n",
    "request = IdMappingClient.submit(\n",
    "    source=\"GeneID\", dest=\"UniProtKB\", ids={str(x) for x in entrez_epi}\n",
    ")\n",
    "time.sleep(1)\n",
    "results_list = list(request.each_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bb2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrez2uniprot = pd.DataFrame(results_list)\n",
    "entrez2uniprot.rename(columns={\"from\": \"Entrez_ID\", \"to\": \"UniProt_ID\"}, inplace=True)\n",
    "#entrez2uniprot.to_csv(\"../results/entrez2uniprot.epilepsy.tsv\", sep=\"\\t\", index=False)\n",
    "entrez2uniprot.groupby(\"Entrez_ID\")['UniProt_ID'].apply(lambda x: ','.join(x)).reset_index()\n",
    "entrez2uniprot['UniProt_ID'] = entrez2uniprot['UniProt_ID'].apply(lambda x: [x for x in x.split(',')])\n",
    "epilepsy_ids = epilepsy_genes.merge(entrez2uniprot)\n",
    "epilepsy_ids = epilepsy_ids.explode(\"UniProt_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa85fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrez2uniprot = pd.read_csv(\"../00-documentation/entrez2uniprot.epilepsy.csv\")\n",
    "entrez2uniprot['Entrez_ID'] = entrez2uniprot['Entrez_ID'].astype('str')\n",
    "entrez2uniprot.groupby(\"Entrez_ID\")['UniProt_ID'].apply(lambda x: ','.join(x)).reset_index()\n",
    "entrez2uniprot['UniProt_ID'] = entrez2uniprot['UniProt_ID'].apply(lambda x: [x for x in x.split(',')])\n",
    "epilepsy_ids = epilepsy_genes.merge(entrez2uniprot)\n",
    "epilepsy_ids = epilepsy_ids.explode(\"UniProt_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6215171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_epi = epilepsy_ids['UniProt_ID'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc2a38e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2849"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniprot_epi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3808462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the orthologues file\n",
    "df_orthologues = pd.read_csv('../03-analysis/03.01-orthofinder/Orthologues/Orthologues_Human.UniProt.renamed/Human.UniProt.renamed__v__Zebrafish.UniProt.renamed.tsv', sep='\\t')\n",
    "\n",
    "# Manipulating dataframe to filter only the epilepsy genes\n",
    "df_orthologues['Human.UniProt.renamed'] = df_orthologues['Human.UniProt.renamed'].apply(lambda x: [x for x in x.split(',')])\n",
    "df_orthologues['Zebrafish.UniProt.renamed'] = df_orthologues['Zebrafish.UniProt.renamed'].apply(lambda x: [x for x in x.split(',')])\n",
    "df_orthologues = df_orthologues.explode('Human.UniProt.renamed').explode('Zebrafish.UniProt.renamed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a742b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "orthologues_epi = df_orthologues[df_orthologues['Human.UniProt.renamed'].isin(uniprot_epi)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "103a8f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Orthogroup                   1261\n",
       "Human.UniProt.renamed        1300\n",
       "Zebrafish.UniProt.renamed    1505\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthologues_epi.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60e735c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = list(orthologues_epi['Human.UniProt.renamed'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "592b41b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_seqs=[]\n",
    "\n",
    "with open(\"../01-data/Human.UniProt.renamed.fasta\", 'r') as f:\n",
    "    for s_record in SeqIO.parse(f, 'fasta'):\n",
    "        name = s_record.id\n",
    "        seq = s_record.seq\n",
    "        if name in filter:\n",
    "            selected_seqs.append(s_record)\n",
    "\n",
    "selected_seqs1=[]\n",
    "selected_seqs2=[]\n",
    "\n",
    "for i in range(len(selected_seqs)):\n",
    "    if i <= 650:\n",
    "        selected_seqs1.append(selected_seqs[i])\n",
    "    else:\n",
    "        selected_seqs2.append(selected_seqs[i])\n",
    "\n",
    "with open(\"../01-data/Human.UniProt.Epi.1.fasta\", 'w') as output_file_handle:\n",
    "    SeqIO.write(selected_seqs1, output_file_handle, 'fasta')\n",
    "    \n",
    "with open(\"../01-data/Human.UniProt.Epi.2.fasta\", 'w') as output_file_handle:\n",
    "    SeqIO.write(selected_seqs2, output_file_handle, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc479d17",
   "metadata": {},
   "source": [
    "## 5. Paralogue analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7448bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174d7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loeading the orthologues file\n",
    "df_orthologues = pd.read_csv('../orthofinder/Orthologues/Orthologues_Human.UniProt.renamed/Human.UniProt.renamed__v__Zebrafish.UniProt.renamed.tsv', sep='\\t')\n",
    "\n",
    "#Separating paralogous genes in human\n",
    "hs_genes = df_orthologues[\"Human.UniProt.renamed\"].str.strip().apply(lambda x: x.split(',')).explode().reset_index(drop=True).to_list()\n",
    "hs_genes = [x.strip() for x in hs_genes]\n",
    "\n",
    "#Separating paralogous genes in zebrafish\n",
    "zb_genes = df_orthologues[\"Zebrafish.UniProt.renamed\"].str.strip().apply(lambda x: x.split(',')).explode().reset_index(drop=True).to_list()\n",
    "zb_genes = [x.strip() for x in zb_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98501f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('../results/orthogroup_alignments.tsv')\n",
    "\n",
    "#Separating paralogous genes in dataframes\n",
    "hs_paralogues = df[(df['query'].isin(hs_genes)) & (df['target_id'].isin(hs_genes))]\n",
    "zb_paralogues = df[(df['query'].isin(zb_genes)) & (df['target_id'].isin(zb_genes))]\n",
    "\n",
    "#Separating orthologous genes in dataframes\n",
    "zb_hs_orthologues = df[(df['query'].isin(zb_genes)) & (df['target_id'].isin(hs_genes))]\n",
    "\n",
    "#Saving dataframes\n",
    "hs_paralogues.to_csv('../results/hs_paralogues.all.tsv', sep='\\t', index=False)\n",
    "zb_paralogues.to_csv('../results/zb_paralogues.all.tsv', sep='\\t', index=False)\n",
    "zb_hs_orthologues.to_csv('../results/zb_hs_orthologues.all.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
